{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChestXRayResNet50",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8hgA-jTVLH",
        "colab_type": "text"
      },
      "source": [
        "Healthcare is an extremely important part of the technological revolution, with deep learning techniques being applied to more and more medical problems. \n",
        "\n",
        "This dataset for the detection of pneumonia, using chest x-ray images (https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) is used for binary classification (whether the person is normal or has pneumonia). \n",
        "\n",
        "This notebook was executed in a Google Colab environment, and used transfer learning from a ResNet50 architecture, and after just 10 epochs of training, I was able to achieve **>80% accuracy**. Some minor tweaks and additional architectural changes can definitely increase the accuracy to close to 90% and maybe, even beyond that. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVSdJ3UtURuJ",
        "colab_type": "text"
      },
      "source": [
        "Using this very simple code, we can use the Kaggle API to download the dataset into our environment. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxhATxn9KCWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2b167344-eaf3-415e-97e0-e9aa5b25ccd1"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"##########\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"###################\" # key from the json file\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [00:30<00:00, 24.3MB/s]\n",
            "100% 2.29G/2.29G [00:30<00:00, 80.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ibqNMApUaNN",
        "colab_type": "text"
      },
      "source": [
        "Next, the file has to be unzipped (it is in zip format) and the directories are specified for the train, test and validation sets, as well as the normal and pneumonia directories for the train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6A6xQ0YKLIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "local_zip = '/content/chest-xray-pneumonia.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8GrPhRdKfAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/chest_xray'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCHSqworK7Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_normal_dir = os.path.join(train_dir,'NORMAL')\n",
        "train_pneu_dir = os.path.join(train_dir,'PNEUMONIA')\n",
        "validation_normal_dir = os.path.join(validation_dir,'NORMAL')\n",
        "validation_pneu_dir = os.path.join(validation_dir,'PNEUMONIA')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHH0j7ZsK-yd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2ccf9e11-3117-42f2-b37d-796107265d1f"
      },
      "source": [
        "print('total training normal images:', len(os.listdir(train_normal_dir)))\n",
        "print('total training pneu images:', len(os.listdir(train_pneu_dir)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training normal images: 1341\n",
            "total training pneu images: 3875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6CTw_qUtJe",
        "colab_type": "text"
      },
      "source": [
        "There are 1341 normal images and 3875 pneumonia images in the training set, which seems to be more than sufficient. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKpbxMyZLAxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNeIjc8FU3u5",
        "colab_type": "text"
      },
      "source": [
        "We specify a constant image size to make things uniform for the model to input. We then input the ResNet50 architecture, and ensure it cannot be trained, and that we retain all the weights. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDY_BM3tMc0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "73764971-52f9-4043-eb4d-c7480060da75"
      },
      "source": [
        "img_size=[224,224]\n",
        "model=tf.keras.applications.resnet50.ResNet50(input_shape=img_size + [3], weights='imagenet', include_top=False)\n",
        "model.trainable = False"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9mrtglUVFDp",
        "colab_type": "text"
      },
      "source": [
        "The last layer of the architecture is the 'conv5_block3_out', with a shape of (7,7,2048) which we will use later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXuTx-EYNDQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf42d2bb-b012-46c2-d494-a314a33a2581"
      },
      "source": [
        "last_layer = model.get_layer('conv5_block3_out')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXgHFkmxVUUl",
        "colab_type": "text"
      },
      "source": [
        "We then specify 2 last layers, a dense layer with 1024 nodes, with a 20% dropout rate to prevent overfitting, as well as a final dense layer with a single node and a sigmoid activation (which outputs 0 or 1 to classify)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFbtTX_pOaNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZJZiUWVOvWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amodel=Model(model.input,x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpWne9vaVsq5",
        "colab_type": "text"
      },
      "source": [
        "The layers of our new model (amodel) and their shapes can be seen using the summary() function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViMMDMH4PHa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ddc4d37-f763-40fc-f479-74a5ce08601b"
      },
      "source": [
        "amodel.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         102761472   flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 126,350,209\n",
            "Trainable params: 102,762,497\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JzTGx9PPQx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "amodel.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW7E5NjvV4Ii",
        "colab_type": "text"
      },
      "source": [
        "Compiling the model using RMSProp as the optimizer and a binary_crossentropy loss because of the 2 classes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Next, we use the ImageDataGenerator function in keras to import the images and perform some augmentation on them, as well as to specify some arguments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Aik0CPPgQG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fcae6e4b-402b-458b-fb7d-36d846ea1c29"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (224, 224))     \n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (224, 224))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlHWc_itWSEL",
        "colab_type": "text"
      },
      "source": [
        "There are 5216 training images and 16 validation images. \n",
        "\n",
        "All that's left is to run the model for just 10 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN03zKsnPzpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "88a03a3c-f8d9-457c-ffcc-23312f7ca4a5"
      },
      "source": [
        "history = amodel.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 10,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 - 47s - loss: 0.8222 - accuracy: 0.6995 - val_loss: 0.6554 - val_accuracy: 0.5625\n",
            "Epoch 2/10\n",
            "100/100 - 45s - loss: 0.5184 - accuracy: 0.7490 - val_loss: 0.6276 - val_accuracy: 0.6250\n",
            "Epoch 3/10\n",
            "100/100 - 46s - loss: 0.4954 - accuracy: 0.7555 - val_loss: 0.7007 - val_accuracy: 0.5625\n",
            "Epoch 4/10\n",
            "100/100 - 46s - loss: 0.4552 - accuracy: 0.7710 - val_loss: 0.9272 - val_accuracy: 0.5625\n",
            "Epoch 5/10\n",
            "100/100 - 45s - loss: 0.4410 - accuracy: 0.7835 - val_loss: 0.9437 - val_accuracy: 0.5625\n",
            "Epoch 6/10\n",
            "100/100 - 45s - loss: 0.4338 - accuracy: 0.7871 - val_loss: 0.5694 - val_accuracy: 0.6250\n",
            "Epoch 7/10\n",
            "100/100 - 45s - loss: 0.4113 - accuracy: 0.7920 - val_loss: 0.9337 - val_accuracy: 0.5625\n",
            "Epoch 8/10\n",
            "100/100 - 45s - loss: 0.4150 - accuracy: 0.8001 - val_loss: 0.9175 - val_accuracy: 0.5625\n",
            "Epoch 9/10\n",
            "100/100 - 45s - loss: 0.4003 - accuracy: 0.8055 - val_loss: 0.7112 - val_accuracy: 0.6875\n",
            "Epoch 10/10\n",
            "100/100 - 46s - loss: 0.3825 - accuracy: 0.8155 - val_loss: 0.6212 - val_accuracy: 0.6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxEfawzTWbzz",
        "colab_type": "text"
      },
      "source": [
        "We get 81% accuracy after 10 epochs. Validation accuracy is around 62%. Other architectures such as VGG16 or VGG19 can also be used, and may increase the accuracy. \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "We can plot the training and validation accuracy and see how training occurred. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE9CFLQkQOHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "76d01def-66d7-42fd-d113-5bb4b57f9f5e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1s1eo46Wtuq",
        "colab_type": "text"
      },
      "source": [
        "Training accuracy seems to be steadily increasing, but validation accuracy seems to have peaks and valleys, but overall it does increase. This might be a sign of some overfitting, but definitely not a large amount of overfitting. "
      ]
    }
  ]
}